{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash-mahandargi/Basic-Projects-/blob/main/NLP_and_Naive_Bayes_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the specified path.\n",
        "# The file is a CSV despite having an .xls extension.\n",
        "df = pd.read_csv(\"/content/blogs.csv.xls\")\n",
        "\n",
        "# Display the first few rows of the DataFrame to get a glimpse of the data.\n",
        "display(df.head())\n",
        "# Print the names of the columns in the DataFrame.\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "pPV1Wux8ow2T",
        "outputId": "1ad57dd1-b3a3-412d-c8f7-f30c78dc7522"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Data       Labels\n",
              "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
              "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
              "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
              "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
              "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c142f1da-0c39-4f56-bf41-e76181b40cc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c142f1da-0c39-4f56-bf41-e76181b40cc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c142f1da-0c39-4f56-bf41-e76181b40cc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c142f1da-0c39-4f56-bf41-e76181b40cc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a99e3514-a9c1-4a86-9d2d-54f275d71de9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a99e3514-a9c1-4a86-9d2d-54f275d71de9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a99e3514-a9c1-4a86-9d2d-54f275d71de9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Newsgroups: alt.atheism\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!zaphod.mps.ohio-state.edu!moe.ksu.ksu.edu!osuunx.ucc.okstate.edu!constellation!darkside!okcforum.osrhe.edu!bil\\nFrom: bil@okcforum.osrhe.edu (Bill Conner)\\nSubject: Re: Not the Omni!\\nMessage-ID: <C4vznz.JM4@darkside.osrhe.uoknor.edu>\\nSender: news@darkside.osrhe.uoknor.edu\\nNntp-Posting-Host: okcforum.osrhe.edu\\nOrganization: Okcforum Unix Users Group\\nX-Newsreader: TIN [version 1.1 PL6]\\nReferences: <65785@mimsy.umd.edu>\\nDate: Sat, 3 Apr 1993 02:45:35 GMT\\nLines: 18\\n\\nCharley Wingate (mangoe@cs.umd.edu) wrote:\\n: \\n: >> Please enlighten me.  How is omnipotence contradictory?\\n: \\n: >By definition, all that can occur in the universe is governed by the rules\\n: >of nature. Thus god cannot break them. Anything that god does must be allowed\\n: >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\\n: >the rules of nature.\\n: \\n: Obviously, an omnipotent god can change the rules.\\n\\nWhen you say, \\\"By definition\\\", what exactly is being defined;\\ncertainly not omnipotence. You seem to be saying that the \\\"rules of\\nnature\\\" are pre-existant somehow, that they not only define nature but\\nactually cause it. If that's what you mean I'd like to hear your\\nfurther thoughts on the question.\\n\\nBill\\n\",\n          \"Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53485 talk.religion.misc:83858 talk.origins:40979\\nNewsgroups: alt.atheism,talk.religion.misc,talk.origins\\nPath: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!zaphod.mps.ohio-state.edu!rphroy!caen!uunet!pipex!uknet!warwick!nott-cs!mips.nott.ac.uk!eczcaw\\nFrom: eczcaw@mips.nott.ac.uk (C.Wainwright)\\nSubject: Re: Rawlins debunks creationism\\nMessage-ID: <1993Apr21.093808.1462@cs.nott.ac.uk>\\nSender: news@cs.nott.ac.uk\\nReply-To: eczcaw@mips.nott.ac.uk (C.Wainwright)\\nOrganization: Nottingham University\\nReferences: <1r15rvINNh8p@ctron-news.ctron.com> <30147@ursa.bear.com> <C5snCL.J8o@usenet.ucs.indiana.edu> <30151@ursa.bear.com>\\nDate: Wed, 21 Apr 93 09:38:08 GMT\\nLines: 51\\n\\nIn article <30151@ursa.bear.com>, halat@pooh.bears (Jim Halat) writes:\\n|> In article <C5snCL.J8o@usenet.ucs.indiana.edu>, adpeters@sunflower.bio.indiana.edu (Andy Peters) writes:\\n|> \\n|> >Evolution, as I have said before, is theory _and_ fact.  It is exactly\\n|> >the same amount of each as the existence of atoms and the existence of\\n|> >gravity.  If you accept the existence of atoms and gravity as fact,\\n|> >then you should also accept the existence of evolution as fact.\\n|> >\\n|> >-- \\n|> >--Andy\\n|> \\n|> I don't accept atoms or gravity as fact either.  They are extremely useful\\n|> mathematical models to describe physical observations we can make.\\n|> Other posters have aptly explained the atomic model.  Gravity, too, is\\n|> very much a theory; no gravity waves have even been detected, but we\\n|> have a very useful model that describes much of the behavior on\\n|> objects by this thing we _call_ gravity.  Gravity, however, is _not_ \\n|> a fact.  It is a theoretical model used to talk about how objects \\n|> behave in our physical environment.  Newton thought gravity was a\\n|> simple vector force; Einstein a wave. Both are very useful models that \\n|> have no religious overtones or requirements of faith, unless of course you \\n|> want to demand that it is a factual physical entity described exactly \\n|> the way the theory now formulated talks about it.  That takes a great \\n|> leap of faith, which, of course, is what religion takes.  Evolution\\n|> is no different.\\n|> \\n|> -- \\n|>  jim halat         halat@bear.com     \\n|> bear-stearns       --whatever doesn't kill you will only serve to annoy you--\\n|>    nyc             i speak only for myself\\n|> \\n|> \\n|> \\n|> \\n\\n\\nPerhaps the major difference here is that we notice something, which we call\\ngravity, and then do some modelling around it.  I myself do not notice any\\ndeity.  Hence a model cannot be made.  A deity is an abstract, and hence\\nreligion may be considered a model of an abstract.\\n\\nBesides, we can always change the model of gravity if the one we have doesn't\\nwork too well.  Can you imagine this with the bible?  Erm, excuse me, I bought\\nthis about 1500 years ago and it doesn't seem quite right...can I have an\\nimproved model please?!\\n-- \\n+-------------------------+-----------------------------------------------+\\n|  Adda Wainwright        |    Does dim atal y llanw!         8o)         |\\n|  eczcaw@mips.nott.ac.uk |   8o)        Mae .sig 'ma ar werth!           |\\n+-------------------------+-----------------------------------------------+\\n\\n\",\n          \"Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!uunet!olivea!hal.com!decwrl!usenet.coe.montana.edu!news.u.washington.edu!carson.u.washington.edu!jimh\\nFrom: jimh@carson.u.washington.edu (James Hogan)\\nNewsgroups: alt.atheism\\nSubject: Re: Yet more Rushdie [Re: ISLAMIC LAW]\\nKeywords: slander calumny\\nMessage-ID: <1qnqlaINN4jg@shelley.u.washington.edu>\\nDate: 17 Apr 93 02:39:38 GMT\\nReferences: <1993Apr15.212943.15118@bnr.ca> <1993Apr16.171722.159590@zeus.calpoly.edu> <1993Apr16.222525.16024@bnr.ca>\\nOrganization: University of Washington, Seattle\\nLines: 60\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nIn article <1993Apr16.222525.16024@bnr.ca> (Rashid) writes:\\n>In article <1993Apr16.171722.159590@zeus.calpoly.edu>,\\n>jmunch@hertz.elee.calpoly.edu (John Munch) wrote:\\n>> \\n>> In article <1993Apr15.212943.15118@bnr.ca> (Rashid) writes:\\n>> >P.S. I'm not sure about this but I think the charge of \\\"shatim\\\" also\\n>> >applies to Rushdie and may be encompassed under the umbrella\\n>> >of the \\\"fasad\\\" ruling.\\n>> \\n>> Please define the words \\\"shatim\\\" and \\\"fasad\\\" before you use them again.\\n>\\n>My apologies. \\\"Shatim\\\", I believe, refers to slandering or spreading\\n>slander and lies about the Prophets(a.s) - any of the Prophets.\\n\\nBasically, any prophet I've ever dealt with has either been busy \\nhawking stolen merchandise or selling swampland house lots in \\nFlorida.  Then you hear all the stories of sexual abuse by prophets\\nand how the families of victims were paid to keep quiet about it.\\n\\n>It's a kind of willful caulmny and \\\"cursing\\\" that's indicated by the\\n>word. This is the best explanation I can come up with off the top\\n>of my head - I'll try and look up a more technical definition when I\\n>have the time.\\n\\nNever mind that, but let me tell you about this Chevelle I bought \\nfrom this dude (you guessed it, a prophet) named Mohammed.  I've\\ngot the car for like two days when the tranny kicks, then Manny, \\nmy mechanic, tells me it was loaded with sawdust!  Take a guess\\nwhether \\\"Mohammed\\\" was anywhere to be found.  I don't think so.\\n\\n>\\n>\\\"Fasad\\\" is a little more difficult to describe. Again, this is not\\n>a technical definition - I'll try and get that later. Literally,\\n\\nOh, Mohammed!\\n\\n>the word \\\"fasad\\\" means mischief. But it's a mischief on the order of\\n>magnitude indicated by the word \\\"corruption\\\". It's when someone who\\n>is doing something wrong to begin with, seeks to escalate the hurt,\\n\\nYeah, you, Mohammed!\\n\\n>disorder, concern, harm etc. (the mischief) initially caused by their \\n>actions. The \\\"wrong\\\" is specifically related to attacks against\\n>\\\"God and His Messenger\\\" and mischief, corruption, disorder etc.\\n\\nYou slimy mass of pond scum!\\n\\n>resulting from that. The attack need not be a physical attack and there\\n>are different levels of penalty proscribed, depending on the extent\\n>of the mischief and whether the person or persons sought to \\n>\\\"make hay\\\" of the situation. The severest punishment is death.\\n\\nYeah, right!  You're the one should be watching your butt.  You and\\nyour buddy Allah.  The stereo he sold me croaked after two days.\\nYour ass is grass!\\n\\nJim\\n\\nYeah, that's right, Jim.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"alt.atheism\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data', 'Labels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nb_text_sentiment.py\n",
        "\n",
        "# STEP 1: Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# STEP 2: Load the blog dataset (it's a CSV, despite the .xls name)\n",
        "data = pd.read_csv(\"blogs.csv.xls\")\n",
        "print(\"\\nShape of dataset:\", data.shape)\n",
        "print(\"\\nColumns:\", data.columns)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# STEP 3: Clean the text\n",
        "# Define a function to clean the text data.\n",
        "def clean_text(text):\n",
        "    # Convert text to lowercase.\n",
        "    text = text.lower()\n",
        "    # Remove digits from the text.\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    # Remove punctuation from the text.\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Remove leading/trailing whitespace.\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the 'Data' column to create a new 'Cleaned' column.\n",
        "data['Cleaned'] = data['Data'].apply(clean_text)\n",
        "\n",
        "# STEP 4: Tokenize and remove stopwords\n",
        "# Define a function to tokenize the text and remove stopwords.\n",
        "def tokenize_remove_stopwords(text):\n",
        "    # Tokenize the text into words.\n",
        "    tokens = word_tokenize(text)\n",
        "    # Get the set of English stopwords.\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Filter out stopwords from the tokens.\n",
        "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "    # Join the filtered tokens back into a string.\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "# Apply the tokenize_remove_stopwords function to the 'Cleaned' column to create a new 'Processed' column.\n",
        "data['Processed'] = data['Cleaned'].apply(tokenize_remove_stopwords)\n",
        "\n",
        "# Show example after processing\n",
        "print(\"\\nAfter processing:\")\n",
        "print(data[['Data', 'Processed']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4DEu4WAow0p",
        "outputId": "e52ea7bc-1c9b-46c4-9fdc-c47ce7275b0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataset: (2000, 2)\n",
            "\n",
            "Columns: Index(['Data', 'Labels'], dtype='object')\n",
            "\n",
            "First 5 rows:\n",
            "                                                Data       Labels\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
            "\n",
            "After processing:\n",
            "                                                Data  \\\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....   \n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...   \n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...   \n",
            "\n",
            "                                           Processed  \n",
            "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "1  newsgroups altatheism path cantaloupesrvcscmue...  \n",
            "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  \n",
            "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "4  xref cantaloupesrvcscmuedu altatheism talkreli...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a70e6464",
        "outputId": "67f0dd77-1295-4f01-fb41-acba9f17c626"
      },
      "source": [
        "# STEP 5: Split data and vectorize\n",
        "# Split the data into training and testing sets. 80% for training, 20% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Processed'], data['Labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a TfidfVectorizer to convert text data into TF-IDF features.\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Fit the vectorizer on the training data and transform the training data.\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "# Transform the testing data using the fitted vectorizer.\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Print the shapes of the resulting training and testing data matrices.\n",
        "print(\"Shape of training data:\", X_train_vec.shape)\n",
        "print(\"Shape of testing data:\", X_test_vec.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (1600, 41212)\n",
            "Shape of testing data: (400, 41212)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains redundant code for splitting data and vectorizing\n",
        "# which was already performed in cell a70e6464.\n",
        "# Keeping it for context, but the subsequent modeling in cell e06788f2 uses the output from cell a70e6464.\n",
        "\n",
        "\n",
        "# STEP 5: Convert text to TF-IDF features\n",
        "# Initialize a TfidfVectorizer to convert text data into TF-IDF features.\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Fit and transform the 'Processed' text data to create TF-IDF features.\n",
        "X = vectorizer.fit_transform(data['Processed'])\n",
        "\n",
        "# STEP 6: Encode target labels and split data\n",
        "# Get the target labels.\n",
        "y = data['Labels']\n",
        "# Split the data into training and testing sets. 80% for training, 20% for testing.\n",
        "# This split is redundant as it's also done in cell a70e6464.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# STEP 7: Train Naive Bayes model\n",
        "# Initialize a Multinomial Naive Bayes model.\n",
        "model = MultinomialNB()\n",
        "# Train the model using the training data.\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# STEP 8: Evaluate the model\n",
        "# Make predictions on the test set.\n",
        "y_pred = model.predict(X_test)\n",
        "# Print the classification report showing precision, recall, f1-score, and support.\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# Print the overall accuracy of the model.\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OaEY6Whmex_",
        "outputId": "8176c672-0784-4888-9e32-be10334824eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.53      0.89      0.67        18\n",
            "           comp.graphics       0.76      0.89      0.82        18\n",
            " comp.os.ms-windows.misc       0.95      0.91      0.93        22\n",
            "comp.sys.ibm.pc.hardware       0.90      0.76      0.83        25\n",
            "   comp.sys.mac.hardware       0.83      0.90      0.86        21\n",
            "          comp.windows.x       1.00      0.84      0.91        25\n",
            "            misc.forsale       1.00      0.72      0.84        18\n",
            "               rec.autos       0.89      0.94      0.92        18\n",
            "         rec.motorcycles       0.88      0.88      0.88        16\n",
            "      rec.sport.baseball       0.83      0.83      0.83        18\n",
            "        rec.sport.hockey       0.83      1.00      0.91        15\n",
            "               sci.crypt       0.83      1.00      0.90        19\n",
            "         sci.electronics       0.70      0.88      0.78        16\n",
            "                 sci.med       0.88      0.88      0.88        17\n",
            "               sci.space       1.00      0.90      0.95        21\n",
            "  soc.religion.christian       0.85      0.96      0.90        23\n",
            "      talk.politics.guns       0.92      0.79      0.85        28\n",
            "   talk.politics.mideast       1.00      0.95      0.97        20\n",
            "      talk.politics.misc       0.68      0.94      0.79        18\n",
            "      talk.religion.misc       0.67      0.17      0.27        24\n",
            "\n",
            "                accuracy                           0.84       400\n",
            "               macro avg       0.85      0.85      0.83       400\n",
            "            weighted avg       0.85      0.84      0.83       400\n",
            "\n",
            "Accuracy: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "to-b0duNmetk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06788f2",
        "outputId": "2e4941b1-74c4-4bf1-a97d-affeb0adfc4f"
      },
      "source": [
        "# STEP 6: Train Naive Bayes model\n",
        "# Initialize a Multinomial Naive Bayes model.\n",
        "model = MultinomialNB()\n",
        "# Train the model using the vectorized training data from cell a70e6464.\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# STEP 7: Evaluate the model\n",
        "# Make predictions on the vectorized test set from cell a70e6464.\n",
        "y_pred = model.predict(X_test_vec)\n",
        "# Print the classification report showing precision, recall, f1-score, and support.\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# Print the overall accuracy of the model.\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.53      0.89      0.67        18\n",
            "           comp.graphics       0.80      0.89      0.84        18\n",
            " comp.os.ms-windows.misc       0.95      0.95      0.95        22\n",
            "comp.sys.ibm.pc.hardware       0.91      0.80      0.85        25\n",
            "   comp.sys.mac.hardware       0.79      0.90      0.84        21\n",
            "          comp.windows.x       1.00      0.84      0.91        25\n",
            "            misc.forsale       1.00      0.72      0.84        18\n",
            "               rec.autos       0.89      0.94      0.92        18\n",
            "         rec.motorcycles       0.93      0.88      0.90        16\n",
            "      rec.sport.baseball       0.80      0.89      0.84        18\n",
            "        rec.sport.hockey       0.88      1.00      0.94        15\n",
            "               sci.crypt       0.83      1.00      0.90        19\n",
            "         sci.electronics       0.72      0.81      0.76        16\n",
            "                 sci.med       0.88      0.88      0.88        17\n",
            "               sci.space       1.00      0.90      0.95        21\n",
            "  soc.religion.christian       0.85      0.96      0.90        23\n",
            "      talk.politics.guns       0.92      0.79      0.85        28\n",
            "   talk.politics.mideast       1.00      0.95      0.97        20\n",
            "      talk.politics.misc       0.68      0.94      0.79        18\n",
            "      talk.religion.misc       0.67      0.17      0.27        24\n",
            "\n",
            "                accuracy                           0.84       400\n",
            "               macro avg       0.85      0.86      0.84       400\n",
            "            weighted avg       0.86      0.84      0.84       400\n",
            "\n",
            "Accuracy: 0.845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1952d3c3",
        "outputId": "66732d56-f4fa-424c-a593-1e76d1fed0a7"
      },
      "source": [
        "# STEP 9: Sentiment Analysis\n",
        "# Import the TextBlob library for sentiment analysis.\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Define a function to get the sentiment of a given text.\n",
        "def get_sentiment(text):\n",
        "    # Calculate the polarity of the text using TextBlob.\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    # Categorize sentiment based on polarity.\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Apply the get_sentiment function to the 'Data' column to create a new 'Sentiment' column.\n",
        "data['Sentiment'] = data['Data'].apply(get_sentiment)\n",
        "\n",
        "# Show sample sentiment from the first few rows.\n",
        "print(\"\\nSentiment examples:\")\n",
        "print(data[['Data', 'Sentiment']].head())\n",
        "\n",
        "# Show sentiment distribution by category by grouping by 'Labels' and 'Sentiment'.\n",
        "print(\"\\nSentiment distribution across categories:\")\n",
        "print(data.groupby(['Labels', 'Sentiment']).size().unstack(fill_value=0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment examples:\n",
            "                                                Data Sentiment\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Positive\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  Negative\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  Positive\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Positive\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  Positive\n",
            "\n",
            "Sentiment distribution across categories:\n",
            "Sentiment                 Negative  Positive\n",
            "Labels                                      \n",
            "alt.atheism                     23        77\n",
            "comp.graphics                   24        76\n",
            "comp.os.ms-windows.misc         22        78\n",
            "comp.sys.ibm.pc.hardware        20        80\n",
            "comp.sys.mac.hardware           24        76\n",
            "comp.windows.x                  27        73\n",
            "misc.forsale                    16        84\n",
            "rec.autos                       17        83\n",
            "rec.motorcycles                 26        74\n",
            "rec.sport.baseball              29        71\n",
            "rec.sport.hockey                34        66\n",
            "sci.crypt                       19        81\n",
            "sci.electronics                 19        81\n",
            "sci.med                         29        71\n",
            "sci.space                       27        73\n",
            "soc.religion.christian          13        87\n",
            "talk.politics.guns              30        70\n",
            "talk.politics.mideast           22        78\n",
            "talk.politics.misc              22        78\n",
            "talk.religion.misc              14        86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample sentiment from the first few rows.\n",
        "print(\"\\nSentiment examples:\")\n",
        "print(data[['Data', 'Sentiment']].head())\n",
        "\n",
        "# Show sentiment distribution by category by grouping by 'Labels' and 'Sentiment'.\n",
        "print(\"\\nSentiment distribution across categories:\")\n",
        "print(data.groupby(['Labels', 'Sentiment']).size().unstack(fill_value=0))\n",
        "\n",
        "# STEP 10: Export results to CSV\n",
        "# Export the original 'Data', 'Labels', and calculated 'Sentiment' to a CSV file.\n",
        "data[['Data', 'Labels', 'Sentiment']].to_csv(\"classified_sentiment_output.csv\", index=False)\n",
        "print(\"\\nExported results to 'classified_sentiment_output.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQc06D4mo0Q-",
        "outputId": "02677738-e46a-456f-874d-042630bc7d62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment examples:\n",
            "                                                Data Sentiment\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Positive\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  Negative\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  Positive\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Positive\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  Positive\n",
            "\n",
            "Sentiment distribution across categories:\n",
            "Sentiment                 Negative  Positive\n",
            "Labels                                      \n",
            "alt.atheism                     23        77\n",
            "comp.graphics                   24        76\n",
            "comp.os.ms-windows.misc         22        78\n",
            "comp.sys.ibm.pc.hardware        20        80\n",
            "comp.sys.mac.hardware           24        76\n",
            "comp.windows.x                  27        73\n",
            "misc.forsale                    16        84\n",
            "rec.autos                       17        83\n",
            "rec.motorcycles                 26        74\n",
            "rec.sport.baseball              29        71\n",
            "rec.sport.hockey                34        66\n",
            "sci.crypt                       19        81\n",
            "sci.electronics                 19        81\n",
            "sci.med                         29        71\n",
            "sci.space                       27        73\n",
            "soc.religion.christian          13        87\n",
            "talk.politics.guns              30        70\n",
            "talk.politics.mideast           22        78\n",
            "talk.politics.misc              22        78\n",
            "talk.religion.misc              14        86\n",
            "\n",
            "Exported results to 'classified_sentiment_output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jkLl8cgo05w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "bdab6869",
        "outputId": "3f212cc4-4223-4531-ca48-9f6c3650524f"
      },
      "source": [
        "# Continued Data Exploration\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(\"\\nDistribution of Labels:\")\n",
        "print(data['Labels'].value_counts())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3336402879.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Continued Data Exploration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMissing values per column:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDistribution of Labels:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10f0ef80",
        "outputId": "3fc232a6-233f-42ab-8fac-a832c5f530d4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Load the blog dataset (it's a CSV, despite the .xls name)\n",
        "data = pd.read_csv(\"blogs.csv.xls\")\n",
        "print(\"\\nShape of dataset:\", data.shape)\n",
        "print(\"\\nColumns:\", data.columns)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Clean the text\n",
        "# Define a function to clean the text data.\n",
        "def clean_text(text):\n",
        "    # Convert text to lowercase.\n",
        "    text = text.lower()\n",
        "    # Remove digits from the text.\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    # Remove punctuation from the text.\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Remove leading/trailing whitespace.\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the 'Data' column to create a new 'Cleaned' column.\n",
        "data['Cleaned'] = data['Data'].apply(clean_text)\n",
        "\n",
        "# Tokenize and remove stopwords\n",
        "# Define a function to tokenize the text and remove stopwords.\n",
        "def tokenize_remove_stopwords(text):\n",
        "    # Tokenize the text into words.\n",
        "    tokens = word_tokenize(text)\n",
        "    # Get the set of English stopwords.\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Filter out stopwords from the tokens.\n",
        "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "    # Join the filtered tokens back into a string.\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "# Apply the tokenize_remove_stopwords function to the 'Cleaned' column to create a new 'Processed' column.\n",
        "data['Processed'] = data['Cleaned'].apply(tokenize_remove_stopwords)\n",
        "\n",
        "# Show example after processing\n",
        "print(\"\\nAfter processing:\")\n",
        "print(data[['Data', 'Processed']].head())\n",
        "\n",
        "# Continued Data Exploration\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(\"\\nDistribution of Labels:\")\n",
        "print(data['Labels'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataset: (2000, 2)\n",
            "\n",
            "Columns: Index(['Data', 'Labels'], dtype='object')\n",
            "\n",
            "First 5 rows:\n",
            "                                                Data       Labels\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
            "\n",
            "After processing:\n",
            "                                                Data  \\\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....   \n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...   \n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...   \n",
            "\n",
            "                                           Processed  \n",
            "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "1  newsgroups altatheism path cantaloupesrvcscmue...  \n",
            "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  \n",
            "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "4  xref cantaloupesrvcscmuedu altatheism talkreli...  \n",
            "\n",
            "Missing values per column:\n",
            "Data         0\n",
            "Labels       0\n",
            "Cleaned      0\n",
            "Processed    0\n",
            "dtype: int64\n",
            "\n",
            "Distribution of Labels:\n",
            "Labels\n",
            "alt.atheism                 100\n",
            "comp.graphics               100\n",
            "comp.os.ms-windows.misc     100\n",
            "comp.sys.ibm.pc.hardware    100\n",
            "comp.sys.mac.hardware       100\n",
            "comp.windows.x              100\n",
            "misc.forsale                100\n",
            "rec.autos                   100\n",
            "rec.motorcycles             100\n",
            "rec.sport.baseball          100\n",
            "rec.sport.hockey            100\n",
            "sci.crypt                   100\n",
            "sci.electronics             100\n",
            "sci.med                     100\n",
            "sci.space                   100\n",
            "soc.religion.christian      100\n",
            "talk.politics.guns          100\n",
            "talk.politics.mideast       100\n",
            "talk.politics.misc          100\n",
            "talk.religion.misc          100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47695bb7"
      },
      "source": [
        "## Evaluation and Reflection\n",
        "\n",
        "**Naive Bayes Model Evaluation:**\n",
        "\n",
        "The Multinomial Naive Bayes model was evaluated using the accuracy, precision, recall, and F1-score metrics. The classification report provides a detailed breakdown of these metrics for each category.\n",
        "\n",
        "*   **Accuracy:** The overall accuracy of the model is [Insert Accuracy Score from cell e06788f2 output]. This indicates the percentage of correctly classified blog posts.\n",
        "*   **Precision:** Precision measures the ability of the model to correctly identify positive instances (i.e., when it predicts a category, how often is it correct?).\n",
        "*   **Recall:** Recall measures the ability of the model to find all positive instances (i.e., of all the instances that actually belong to a category, how many did the model correctly identify?).\n",
        "*   **F1-score:** The F1-score is the harmonic mean of precision and recall, providing a balanced measure of the model's performance.\n",
        "\n",
        "Looking at the classification report, we can observe the model's performance across different blog categories. Some categories have higher precision and recall than others, which could be due to factors like the amount of training data available for that category or the distinctiveness of the language used in those blogs.\n",
        "\n",
        "**Challenges Encountered:**\n",
        "\n",
        "One potential challenge in this classification task is the inherent ambiguity in text data. Blog posts can sometimes overlap in topics or use language that is not strictly confined to a single category, which can make it difficult for the model to make accurate predictions. The preprocessing steps, while helpful, might also remove some context that could be useful for classification.\n",
        "\n",
        "**Sentiment Analysis Reflection:**\n",
        "\n",
        "The sentiment analysis using TextBlob provided insights into the emotional tone of the blog posts across different categories. The distribution of sentiments shows that [Discuss the general distribution of positive, negative, and neutral sentiments across categories based on the output of cell jQc06D4mo0Q-].\n",
        "\n",
        "It's interesting to observe if certain categories tend to have a higher proportion of positive or negative sentiments. This could reflect the nature of the discussions within those communities. For example, categories related to politics might have more negative sentiment compared to categories related to hobbies or sports.\n",
        "\n",
        "It's important to note that rule-based sentiment analysis methods like TextBlob might not always capture the nuances of human language, such as sarcasm or irony. Therefore, the sentiment results should be interpreted with this limitation in mind.\n",
        "\n",
        "Overall, the sentiment analysis provides a valuable layer of understanding to the blog data, complementing the topic classification performed by the Naive Bayes model."
      ]
    }
  ]
}