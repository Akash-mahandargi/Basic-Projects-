{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW6MvYXTB2HLVwIbce30A/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash-mahandargi/Basic-Projects-/blob/main/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "Ij2XfNVRiPoB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")\n",
        "\n",
        "# Step 3: Explore the dataset\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "print(\"Missing values:\\n\", df.isnull().sum())\n",
        "print(\"Class distribution:\\n\", df.iloc[:, -1].value_counts())\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "An6VWvZhiPqF",
        "outputId": "be69ce68-caca-48b6-f01d-11a18f29a349"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: (20000, 17)\n",
            "Missing values:\n",
            " letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n",
            "Class distribution:\n",
            " yedgex\n",
            "8     8047\n",
            "7     3472\n",
            "9     2358\n",
            "6     1827\n",
            "10    1578\n",
            "5      992\n",
            "11     868\n",
            "4      478\n",
            "12     137\n",
            "3      130\n",
            "13      49\n",
            "2       30\n",
            "1       17\n",
            "14      13\n",
            "15       2\n",
            "0        2\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
              "0      T     2     8      3       5      1     8    13      0      6      6   \n",
              "1      I     5    12      3       7      2    10     5      5      4     13   \n",
              "2      D     4    11      6       8      6    10     6      2      6     10   \n",
              "3      N     7    11      6       6      3     5     9      4      6      4   \n",
              "4      G     2     1      3       1      1     8     6      6      6      6   \n",
              "\n",
              "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
              "0      10       8      0       8      0       8  \n",
              "1       3       9      2       8      4      10  \n",
              "2       3       7      3       7      3       9  \n",
              "3       4      10      6      10      2       8  \n",
              "4       5       9      1       7      5      10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f9f0531-fc90-4968-9d0e-b23db58ad2c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>xbox</th>\n",
              "      <th>ybox</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>onpix</th>\n",
              "      <th>xbar</th>\n",
              "      <th>ybar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybar</th>\n",
              "      <th>xy2bar</th>\n",
              "      <th>xedge</th>\n",
              "      <th>xedgey</th>\n",
              "      <th>yedge</th>\n",
              "      <th>yedgex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f9f0531-fc90-4968-9d0e-b23db58ad2c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f9f0531-fc90-4968-9d0e-b23db58ad2c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f9f0531-fc90-4968-9d0e-b23db58ad2c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e627cefc-e9e6-404f-b820-10cfd512759a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e627cefc-e9e6-404f-b820-10cfd512759a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e627cefc-e9e6-404f-b820-10cfd512759a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"letter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"J\",\n          \"W\",\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          2,\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          12,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3,\n          6,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          5,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"onpix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          13,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          10,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xy2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          2,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedgey\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          7,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          4,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedgex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Encode labels (if they are letters like A, B, C...)\n",
        "le = LabelEncoder()\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])  # encode the labels (e.g., A → 0)\n",
        "\n",
        "# Step 5: Split features and target\n",
        "X = df.iloc[:, :-1]  # all columns except last\n",
        "y = df.iloc[:, -1]   # last column\n"
      ],
      "metadata": {
        "id": "Fy9JL4vkiPs-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "source": [
        "X = df.iloc[:, 1:-1] # all columns except first ('letter') and last (target)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SKpxaJ4PiuIm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "Hda9KNobiPui"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "8chmbD3yiPwU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Define the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # 1 hidden layer with 64 neurons\n",
        "model.add(Dense(32, activation='relu'))                                   # 2nd hidden layer\n",
        "model.add(Dense(len(np.unique(y)), activation='softmax'))                 # Output layer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2d3DRkSixUg",
        "outputId": "33fc4b03-7696-4fb1-fa23-df2a14610d66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSL_NYSRiYxI",
        "outputId": "8e506221-f814-44fd-c133-289807df2fc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3107 - loss: 2.1134 - val_accuracy: 0.4769 - val_loss: 1.3979\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4851 - loss: 1.3555 - val_accuracy: 0.5063 - val_loss: 1.2509\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 1.2351 - val_accuracy: 0.5406 - val_loss: 1.1804\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5406 - loss: 1.1841 - val_accuracy: 0.5531 - val_loss: 1.1439\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5604 - loss: 1.1407 - val_accuracy: 0.5669 - val_loss: 1.1122\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5740 - loss: 1.0965 - val_accuracy: 0.5600 - val_loss: 1.0978\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5832 - loss: 1.0730 - val_accuracy: 0.5550 - val_loss: 1.1040\n",
            "Epoch 8/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 1.0532 - val_accuracy: 0.5744 - val_loss: 1.0720\n",
            "Epoch 9/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 1.0320 - val_accuracy: 0.5900 - val_loss: 1.0474\n",
            "Epoch 10/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 1.0098 - val_accuracy: 0.5906 - val_loss: 1.0433\n",
            "Epoch 11/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 1.0098 - val_accuracy: 0.5894 - val_loss: 1.0391\n",
            "Epoch 12/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 0.9927 - val_accuracy: 0.5962 - val_loss: 1.0221\n",
            "Epoch 13/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 0.9775 - val_accuracy: 0.6019 - val_loss: 1.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6265 - loss: 0.9615 - val_accuracy: 0.6050 - val_loss: 1.0134\n",
            "Epoch 15/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.9547 - val_accuracy: 0.6075 - val_loss: 1.0035\n",
            "Epoch 16/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6312 - loss: 0.9416 - val_accuracy: 0.6150 - val_loss: 1.0053\n",
            "Epoch 17/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6377 - loss: 0.9350 - val_accuracy: 0.6112 - val_loss: 0.9992\n",
            "Epoch 18/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6405 - loss: 0.9207 - val_accuracy: 0.6075 - val_loss: 1.0053\n",
            "Epoch 19/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6395 - loss: 0.9128 - val_accuracy: 0.6175 - val_loss: 0.9867\n",
            "Epoch 20/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 0.9136 - val_accuracy: 0.6187 - val_loss: 0.9816\n",
            "Epoch 21/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6448 - loss: 0.9143 - val_accuracy: 0.6212 - val_loss: 0.9846\n",
            "Epoch 22/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.9040 - val_accuracy: 0.6200 - val_loss: 0.9780\n",
            "Epoch 23/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6471 - loss: 0.8944 - val_accuracy: 0.6150 - val_loss: 0.9731\n",
            "Epoch 24/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6570 - loss: 0.8688 - val_accuracy: 0.6187 - val_loss: 0.9672\n",
            "Epoch 25/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 0.8833 - val_accuracy: 0.6319 - val_loss: 0.9613\n",
            "Epoch 26/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 0.8734 - val_accuracy: 0.6263 - val_loss: 0.9588\n",
            "Epoch 27/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: 0.8809 - val_accuracy: 0.6300 - val_loss: 0.9542\n",
            "Epoch 28/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.8575 - val_accuracy: 0.6231 - val_loss: 0.9620\n",
            "Epoch 29/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.8509 - val_accuracy: 0.6244 - val_loss: 0.9572\n",
            "Epoch 30/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6643 - loss: 0.8438 - val_accuracy: 0.6250 - val_loss: 0.9554\n",
            "Epoch 31/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.8500 - val_accuracy: 0.6294 - val_loss: 0.9514\n",
            "Epoch 32/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6719 - loss: 0.8366 - val_accuracy: 0.6069 - val_loss: 0.9638\n",
            "Epoch 33/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6656 - loss: 0.8576 - val_accuracy: 0.6294 - val_loss: 0.9467\n",
            "Epoch 34/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6678 - loss: 0.8388 - val_accuracy: 0.6319 - val_loss: 0.9455\n",
            "Epoch 35/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.8307 - val_accuracy: 0.6331 - val_loss: 0.9470\n",
            "Epoch 36/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6721 - loss: 0.8362 - val_accuracy: 0.6300 - val_loss: 0.9361\n",
            "Epoch 37/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.8209 - val_accuracy: 0.6269 - val_loss: 0.9443\n",
            "Epoch 38/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6771 - loss: 0.8237 - val_accuracy: 0.6319 - val_loss: 0.9354\n",
            "Epoch 39/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.8152 - val_accuracy: 0.6288 - val_loss: 0.9324\n",
            "Epoch 40/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6736 - loss: 0.8225 - val_accuracy: 0.6363 - val_loss: 0.9377\n",
            "Epoch 41/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.8061 - val_accuracy: 0.6338 - val_loss: 0.9364\n",
            "Epoch 42/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.8098 - val_accuracy: 0.6444 - val_loss: 0.9302\n",
            "Epoch 43/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.8139 - val_accuracy: 0.6331 - val_loss: 0.9395\n",
            "Epoch 44/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6777 - loss: 0.8097 - val_accuracy: 0.6394 - val_loss: 0.9375\n",
            "Epoch 45/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6853 - loss: 0.7991 - val_accuracy: 0.6394 - val_loss: 0.9251\n",
            "Epoch 46/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 0.8041 - val_accuracy: 0.6475 - val_loss: 0.9227\n",
            "Epoch 47/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.7907 - val_accuracy: 0.6394 - val_loss: 0.9197\n",
            "Epoch 48/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.7991 - val_accuracy: 0.6406 - val_loss: 0.9269\n",
            "Epoch 49/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 0.7757 - val_accuracy: 0.6375 - val_loss: 0.9265\n",
            "Epoch 50/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.7921 - val_accuracy: 0.6438 - val_loss: 0.9258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 10: Evaluate on test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred_classes))\n",
        "print(classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gCyIdK7iYvE",
        "outputId": "cc341afc-f7d3-411b-c8de-1e44af7a6e2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "[[   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [   0    3    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "     0    0]\n",
            " [   0    2    1    0    0    1    0    0    1    0    1    0    0    0\n",
            "     0    0]\n",
            " [   0    0    1    4   12    1    2    3    2    2    1    2    0    0\n",
            "     0    1]\n",
            " [   0    2    0    2   42   24   11    4    2    1    4    2    0    0\n",
            "     0    0]\n",
            " [   0    0    1    0   15   81   69   11   13    4    0    0    2    0\n",
            "     0    0]\n",
            " [   0    0    0    0    4   19  211   76   26   12    2    2    0    1\n",
            "     0    0]\n",
            " [   0    0    0    0    7    8   98  363  211   18    2    3    1    1\n",
            "     0    0]\n",
            " [   0    0    0    0    1    1    6  115 1361   95   12    4    1    0\n",
            "     0    0]\n",
            " [   0    0    0    1    1    1    9   24  130  262   39   17    1    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    1    1    9   31  102  107   56    0    1\n",
            "     0    0]\n",
            " [   0    0    0    0    0    1    2    1   11   22   14  122    2    0\n",
            "     0    0]\n",
            " [   0    0    0    0    1    0    1    0    5    7    1   12    2    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    1    1    0    0    4    3    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.43      0.75      0.55         4\n",
            "           2       0.33      0.17      0.22         6\n",
            "           3       0.57      0.13      0.21        31\n",
            "           4       0.51      0.45      0.47        94\n",
            "           5       0.59      0.41      0.49       196\n",
            "           6       0.51      0.60      0.55       353\n",
            "           7       0.60      0.51      0.55       712\n",
            "           8       0.76      0.85      0.80      1596\n",
            "           9       0.50      0.54      0.52       485\n",
            "          10       0.58      0.35      0.44       308\n",
            "          11       0.54      0.70      0.61       175\n",
            "          12       0.17      0.07      0.10        29\n",
            "          13       0.00      0.00      0.00         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "          15       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.64      4000\n",
            "   macro avg       0.38      0.34      0.34      4000\n",
            "weighted avg       0.63      0.64      0.63      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48b7bd6c",
        "outputId": "7646742c-b8ea-4cb3-c27b-6c7a53558a70"
      },
      "source": [
        "!pip install keras_tuner"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras_tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file: ann_alphabets_classifier.py\n",
        "\n",
        "# ✅ Step 4: Hyperparameter Tuning using Keras Tuner\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import keras_tuner as kt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ✅ Re-prepare data if kernel was reset\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "# Assuming the last column is the target and the first is 'letter'\n",
        "# and the rest are features. Adjust if your data structure is different.\n",
        "# Encode the target variable (last column)\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
        "\n",
        "# Features and target\n",
        "# Exclude the 'letter' column (first column) and the target column (last column) from features\n",
        "X = df.iloc[:, 1:-1]  # all columns except first and last\n",
        "y = df.iloc[:, -1]   # last column\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model builder function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=256, step=32)\n",
        "    model.add(Dense(units=hp_units_1, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    if hp.Boolean('second_layer'):\n",
        "        hp_units_2 = hp.Int('units_2', min_value=32, max_value=128, step=32)\n",
        "        model.add(Dense(units=hp_units_2, activation='relu'))\n",
        "\n",
        "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='ann_tuning',\n",
        "    project_name='alphabet_classifier'\n",
        ")\n",
        "\n",
        "# Start hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Visual summary of tuning results\n",
        "tuner.results_summary()\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Predict with best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "y_pred_classes_best = np.argmax(y_pred_best, axis=1)\n",
        "\n",
        "# Predict with base model (retrain if needed)\n",
        "base_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(np.unique(y)), activation='softmax')\n",
        "])\n",
        "base_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "base_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_base = base_model.predict(X_test)\n",
        "y_pred_classes_base = np.argmax(y_pred_base, axis=1)\n",
        "\n",
        "# Compare Reports\n",
        "print(\"\\nClassification Report (Base Model):\")\n",
        "print(classification_report(y_test, y_pred_classes_base))\n",
        "\n",
        "print(\"\\nClassification Report (Tuned Model):\")\n",
        "print(classification_report(y_test, y_pred_classes_best))\n",
        "\n",
        "# Plot training history for best trial\n",
        "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "history = best_trial.metrics.get_history(\"val_accuracy\")\n",
        "\n",
        "# Extract epoch and value from the history list\n",
        "# Assuming history is a list of MetricObservation objects with 'step' and 'value' attributes\n",
        "epochs = [h.step for h in history]\n",
        "values = [h.value[0] for h in history] # Access the first element of the value list\n",
        "\n",
        "plt.plot(epochs, values, label='Validation Accuracy')\n",
        "plt.title(\"Best Model Validation Accuracy over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DbP7lZgyBiGX",
        "outputId": "57df5bca-ce6e-47b0-8870-90f59d10643b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.4793750047683716\n",
            "\n",
            "Best val_accuracy So Far: 0.653124988079071\n",
            "Total elapsed time: 00h 04m 38s\n",
            "Results summary\n",
            "Results in ann_tuning/alphabet_classifier\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "units_1: 160\n",
            "second_layer: True\n",
            "learning_rate: 0.001\n",
            "units_2: 64\n",
            "Score: 0.653124988079071\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "second_layer: True\n",
            "learning_rate: 0.01\n",
            "units_2: 64\n",
            "Score: 0.6346874833106995\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "units_1: 224\n",
            "second_layer: False\n",
            "learning_rate: 0.01\n",
            "units_2: 128\n",
            "Score: 0.6274999976158142\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "units_1: 192\n",
            "second_layer: True\n",
            "learning_rate: 0.01\n",
            "units_2: 32\n",
            "Score: 0.6256250143051147\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "second_layer: False\n",
            "learning_rate: 0.01\n",
            "units_2: 128\n",
            "Score: 0.6228125095367432\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "units_1: 64\n",
            "second_layer: False\n",
            "learning_rate: 0.001\n",
            "units_2: 64\n",
            "Score: 0.5746874809265137\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "units_1: 192\n",
            "second_layer: True\n",
            "learning_rate: 0.0001\n",
            "units_2: 32\n",
            "Score: 0.5450000166893005\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "second_layer: False\n",
            "learning_rate: 0.0001\n",
            "units_2: 96\n",
            "Score: 0.5021874904632568\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "second_layer: True\n",
            "learning_rate: 0.0001\n",
            "units_2: 32\n",
            "Score: 0.4793750047683716\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "second_layer: False\n",
            "learning_rate: 0.0001\n",
            "units_2: 96\n",
            "Score: 0.44468748569488525\n",
            "\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 77ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Classification Report (Base Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.33      0.25      0.29         4\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.73      0.26      0.38        31\n",
            "           4       0.67      0.38      0.49        94\n",
            "           5       0.50      0.43      0.46       196\n",
            "           6       0.48      0.54      0.51       353\n",
            "           7       0.52      0.56      0.54       712\n",
            "           8       0.74      0.79      0.77      1596\n",
            "           9       0.52      0.41      0.46       485\n",
            "          10       0.49      0.50      0.49       308\n",
            "          11       0.56      0.57      0.56       175\n",
            "          12       0.29      0.14      0.19        29\n",
            "          13       0.00      0.00      0.00         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.61      4000\n",
            "   macro avg       0.39      0.32      0.34      4000\n",
            "weighted avg       0.60      0.61      0.60      4000\n",
            "\n",
            "\n",
            "Classification Report (Tuned Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      0.50      0.50         4\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.44      0.23      0.30        31\n",
            "           4       0.49      0.57      0.53        94\n",
            "           5       0.55      0.35      0.43       196\n",
            "           6       0.54      0.61      0.57       353\n",
            "           7       0.63      0.51      0.56       712\n",
            "           8       0.75      0.84      0.79      1596\n",
            "           9       0.56      0.42      0.48       485\n",
            "          10       0.47      0.65      0.55       308\n",
            "          11       0.59      0.60      0.59       175\n",
            "          12       0.75      0.10      0.18        29\n",
            "          13       0.33      0.11      0.17         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.64      4000\n",
            "   macro avg       0.44      0.37      0.38      4000\n",
            "weighted avg       0.64      0.64      0.63      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate predictions from base and tuned models\n",
        "print(\"Classification Report (Base Model):\")\n",
        "print(classification_report(y_test, y_pred_classes_base))\n",
        "\n",
        "print(\"Classification Report (Tuned Model):\")\n",
        "print(classification_report(y_test, y_pred_classes_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r_l2LtOBiEY",
        "outputId": "3d0cfc78-f2ab-4453-a4dd-260cd344fa30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Base Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.33      0.25      0.29         4\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.73      0.26      0.38        31\n",
            "           4       0.67      0.38      0.49        94\n",
            "           5       0.50      0.43      0.46       196\n",
            "           6       0.48      0.54      0.51       353\n",
            "           7       0.52      0.56      0.54       712\n",
            "           8       0.74      0.79      0.77      1596\n",
            "           9       0.52      0.41      0.46       485\n",
            "          10       0.49      0.50      0.49       308\n",
            "          11       0.56      0.57      0.56       175\n",
            "          12       0.29      0.14      0.19        29\n",
            "          13       0.00      0.00      0.00         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.61      4000\n",
            "   macro avg       0.39      0.32      0.34      4000\n",
            "weighted avg       0.60      0.61      0.60      4000\n",
            "\n",
            "Classification Report (Tuned Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      0.50      0.50         4\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.44      0.23      0.30        31\n",
            "           4       0.49      0.57      0.53        94\n",
            "           5       0.55      0.35      0.43       196\n",
            "           6       0.54      0.61      0.57       353\n",
            "           7       0.63      0.51      0.56       712\n",
            "           8       0.75      0.84      0.79      1596\n",
            "           9       0.56      0.42      0.48       485\n",
            "          10       0.47      0.65      0.55       308\n",
            "          11       0.59      0.60      0.59       175\n",
            "          12       0.75      0.10      0.18        29\n",
            "          13       0.33      0.11      0.17         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.64      4000\n",
            "   macro avg       0.44      0.37      0.38      4000\n",
            "weighted avg       0.64      0.64      0.63      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}